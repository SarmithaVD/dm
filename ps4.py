# -*- coding: utf-8 -*-
"""PS4

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iinFPt7EeepH8y2mz4AkV3AIWZZuxwJP
"""

import pandas as pd
from itertools import combinations

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv('/content/drive/MyDrive/Classroom/20XT87 - Data Mining Laboratory 2021-26 Batch-8th Sem TCS/Groceries_dataset.csv')



# Group by Date and list transactions
transactions = df.groupby('Date')['itemDescription'].apply(list).tolist()
transactions

# Function to calculate support
def calculate_support(itemsets, transactions):
    total_transactions = len(transactions)
    support_values = {}

    for itemset in itemsets:
        count = sum(1 for transaction in transactions if set(itemset).issubset(set(transaction)))
        support_values[itemset] = count / total_transactions

    return support_values

# Apriori Algorithm
min_support_values = [0.4, 0.5, 0.7]  # threshold values

for min_support in min_support_values:
    print(f"\nRunning Apriori with min_support = {min_support}\n")

    # Step 1: Get unique items and their support
    item_counts = df['itemDescription'].value_counts()
    candidates = {tuple([item]): count / len(transactions) for item, count in item_counts.items() if count / len(transactions) >= min_support}
    frequent_itemsets = {1: candidates}

    # Step 2: Generate higher-order itemsets
    k = 2
    while True:
        prev_itemsets = list(frequent_itemsets[k - 1].keys())
        candidate_itemsets = list(combinations(set().union(*prev_itemsets), k))

        candidate_supports = calculate_support(candidate_itemsets, transactions)
        filtered_candidates = {itemset: support for itemset, support in candidate_supports.items() if support >= min_support}

        if not filtered_candidates:
            break  # Stop if no frequent itemsets found

        frequent_itemsets[k] = filtered_candidates
        k += 1

    # Display results
    print("Frequent Itemsets:")
    for k, itemsets in frequent_itemsets.items():
        print(f"{k}-itemsets:", itemsets)













# -*- coding: utf-8 -*-
"""21PT28_DM_PS5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GJINcPiV3CE42bYb7C_IML0FKwAzhy3u
"""

pip install c45-decision-tree

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier,plot_tree
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import VotingClassifier
from sklearn.ensemble import VotingClassifier, RandomForestClassifier, AdaBoostClassifier
from xgboost import XGBClassifier
from C45 import C45Classifier

"""# QUESTION 1 : DRUG DATASET


---

**DATA READING**
"""

df = pd.read_excel("/content/drive/MyDrive/SEM 8/DATA MINING LAB/PS5/drug200.xlsx")
print(df.head())

"""**DATA PREPROCESSING**"""

# Check for missing values
print("Missing Values:\n", df.isnull().sum())

# Handle missing values
for col in df.columns:
    if df[col].isnull().sum() > 0:  # If missing values exist
        if df[col].dtype == 'object':  # Categorical column
            df[col].fillna(df[col].mode()[0], inplace=True)  # Fill with mode
        else:  # Numerical column
            df[col].fillna(df[col].median(), inplace=True)  # Fill with median

# Verify missing values are handled
print("\nMissing Values After Imputation:\n", df.isnull().sum())

#Encoding categorical variables

label_encoders = {}  # Store encoders for future reference
categorical_cols = ['Sex', 'BP', 'Cholesterol', 'Drug']

for col in categorical_cols:
  le=LabelEncoder()
  df[col]=le.fit_transform(df[col])
  label_encoders[col]=le

print(label_encoders)

# Feature scaling for numerical features

standard_scaler=StandardScaler() #z-score normalisation
numerical_cols=['Age', 'Na_to_K']

for col in numerical_cols:
  df[[col]]=standard_scaler.fit_transform(df[[col]])

print(df.head())

"""**SIGNIFICANT FEATURES EXTRACTION**"""

#Correlation Matrix (Heatmap)
# This calculates the Pearson correlation coefficient between features.
# Helps visualize how strongly features are related to each other and to the target (Drug).
# High correlation with Drug means the feature is important.
# If two features are highly correlated with each other, one can be removed (reducing redundancy).


correlation_matrix=df.corr()

print(correlation_matrix["Drug"])
print("\n\n")
correlatin_with_target= correlation_matrix["Drug"].drop("Drug")
print(correlatin_with_target)

print("\n\n")
threshold=0.2
important_features=correlatin_with_target[abs(correlatin_with_target)>threshold]
print(important_features)
print("\n\n")

selected_features = important_features.index.tolist()
print("Important Features:", selected_features)

plt.figure(figsize=(8,6))
sns.heatmap(correlation_matrix, annot=True, cmap='viridis', fmt=".2f")
plt.title("Feature Correlation Matrix")
plt.show()

"""**CLASSIFICATION - MODEL BUILDING**"""

X= df.drop(columns=['Drug']) #feature variables
y=df['Drug'] #target variable

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

"""**Logistic regression:**"""

logistic_regression_model= LogisticRegression()

logistic_regression_model.fit(X_train, y_train)

y_pred_lr = logistic_regression_model.predict(X_test)

print("Logistic regression accuracy : " , accuracy_score(y_test, y_pred_lr))
print(classification_report(y_test, y_pred_lr))

"""**Decision tree - CART**"""

dc_cart_model = DecisionTreeClassifier(criterion='gini', random_state=42)
dc_cart_model.fit(X_train, y_train)
y_pred_cart = dc_cart_model.predict(X_test)

print("Decision tree - CART accuracy : ", accuracy_score(y_test, y_pred_cart))
print(classification_report(y_test, y_pred_cart))

"""**Decision tree - ID3**"""

dc_id3_model = DecisionTreeClassifier(criterion = 'entropy', random_state=42)
dc_id3_model.fit(X_train, y_train)
y_pred_id3 = dc_id3_model.predict(X_test)

print("Decision tree - ID3 accuracy : ", accuracy_score(y_test, y_pred_id3))
print(classification_report(y_test, y_pred_id3))



rt.fit(X_train,y_train)
y_lr=cart.predict(X_test)
accuracy=accuracy_score(y_test,y_lr)
print("Accuracy score:",accuracy)
print("Classification report:",classification_report(y_test,y_lr))
class_name = ['drugA', 'drugB', 'drugC', 'drugX', 'drugY']
plot_tree(cart,feature_names=X_train.columns.tolist(),class_names=class_name)
plt.show()

id3=DecisionTreeClassifier(criterion="entropy",random_state=42)
id3.fit(X_train,y_train)
y_lr=id3.predict(X_test)
accuracy=accuracy_score(y_test,y_lr)
print("Accuracy score:",accuracy)
print("Classification report:",classification_report(y_test,y_lr))
class_name = ['drugA', 'drugB', 'drugC', 'drugX', 'drugY']
plot_tree(id3,feature_names=X_train.columns.tolist(),class_names=class_name)
plt.show()



"""**Decision tree - C4.5**"""

dc_c45_model=C45Classifier()
dc_c45_model.fit(X_train, y_train)
y_pred_c45 = dc_c45_model.predict(X_test)

print("Decision tree - C4.5 accuracy : ", accuracy_score(y_test, y_pred_c45))
print(classification_report(y_test, y_pred_c45))

"""**Naive Bayes Classifier**"""

nb_model = GaussianNB()
nb_model.fit(X_train, y_train)

y_pred_nb = nb_model.predict(X_test)

print("Naive Bayes Classifier accuracy : ", accuracy_score(y_test, y_pred_nb))
print(classification_report(y_test, y_pred_nb))

"""**Support Vector Machine (SVM)**"""

svm_model=SVC(kernel='linear')
svm_model.fit(X_train, y_train)
y_pred_svm=svm_model.predict(X_test)

print("Support Vector machine accuracy : ", accuracy_score(y_test, y_pred_svm))
print(classification_report(y_test, y_pred_svm))

"""**k-nearest neighbor (KNN)**



"""

knn_model = KNeighborsClassifier(n_neighbors=5) #k=5
knn_model.fit(X_train, y_train)

y_pred_knn=knn_model.predict(X_test)

print("K-nearest neighbor accuracy : ", accuracy_score(y_test, y_pred_knn))
print(classification_report(y_test, y_pred_knn))

"""**Tabulate the mean accuracy score of k-fold cross-validation (k=10) of the models.**



> Cross-validation is a technique used to evaluate the performance of machine learning models by splitting the dataset into multiple training and testing sets. This helps in getting a more reliable accuracy score instead of depending on a single train-test split.



> In k-fold cross-validation, the dataset is divided into k equal parts (folds):



> The model is trained on (k-1) folds.
It is tested on the remaining 1 fold.
This process repeats k times, and the final accuracy is the average of all k iterations.
For example, with k=10, the dataset is split into 10 parts:


> Train on 9 folds, test on 1.
Train on another 9 folds, test on the next 1.
Repeat this process 10 times.
Compute the average accuracy over all iterations.




"""

models = {
    "Logistic Regression": LogisticRegression(),
    "Decision Tree (CART)": DecisionTreeClassifier(criterion='gini'),
    "Decision Tree (ID3)": DecisionTreeClassifier(criterion='entropy'),
    "Naïve Bayes": GaussianNB(),
    "SVM": SVC(kernel='linear'),
    "KNN": KNeighborsClassifier(n_neighbors=5)

}

kf = 10  # Number of folds
cv_results = {}

for model_name, model in models.items():
    scores = cross_val_score(model, X, y, cv=kf, scoring='accuracy')
    print(scores)
    mean_accuracy = scores.mean()
    cv_results[model_name] = mean_accuracy

# Convert results to a DataFrame
cv_results_df = pd.DataFrame(cv_results.items(), columns=['Model', 'Mean Accuracy'])
print("\n\n")
print(cv_results_df)

"""**COMPARING ACCURACIES**"""

#using the mean accuracies

# Sort models by accuracy (optional)
cv_results_df = cv_results_df.sort_values(by="Mean Accuracy", ascending=False)

# Plot bar chart
plt.figure(figsize=(10, 6))
plt.bar(cv_results_df["Model"], cv_results_df["Mean Accuracy"], color=['lightblue', 'lightgreen', 'lightcoral', 'purple', 'bisque', 'plum'])
plt.xlabel("Classification Models")
plt.ylabel("Mean Accuracy Score")
plt.title("Model Comparison: Mean Accuracy (10-Fold Cross-Validation)")
plt.ylim(0, 1)  # Accuracy ranges from 0 to 1
plt.xticks(rotation=30)  # Rotate x-axis labels for better visibility
plt.show()

#using the normal accuracy

models = ['Logistic Regression', 'Decision Tree (CART)', 'Decision Tree (ID3)', 'Naïve Bayes', 'SVM', 'KNN']
accuracies = [
    accuracy_score(y_test, y_pred_lr),
    accuracy_score(y_test, y_pred_cart),
    accuracy_score(y_test, y_pred_id3),
    accuracy_score(y_test, y_pred_nb),
    accuracy_score(y_test, y_pred_svm),
    accuracy_score(y_test, y_pred_knn)
]

plt.figure(figsize=(8,5))
sns.barplot(x=models, y=accuracies, palette='coolwarm')
plt.ylabel('Accuracy')
plt.xticks(rotation=45)
plt.title('Comparison of Classifier Accuracies')
plt.show()

"""**BEST MODEL:**

>




*   Decision Tree Models (CART & ID3) perform the best with 99% accuracy.
*   Logistic Regression & SVM also perform well (95% accuracy), indicating the dataset is linearly separable.

*   Naïve Bayes performs the worst (83.5%), suggesting that the assumption of feature independence does not hold well.
*   KNN (91%) performs decently but is outperformed by Decision Trees.

# QUESTION 2 - OBESITY DATASET

**DATA READING**
"""

df2 = pd.read_csv("/content/drive/MyDrive/SEM 8/DATA MINING LAB/PS5/ObesityDataSet_raw_and_data_synthetic.csv")

print(df2.head())

"""**DATA PREPROCESSING**"""

# Check for missing values
print("Missing Values:\n", df2.isnull().sum())

# Handle missing values
for col in df2.columns:
    if df2[col].isnull().sum() > 0:  # If missing values exist
        if df2[col].dtype == 'object':  # Categorical column
            df2[col].fillna(df2[col].mode()[0], inplace=True)  # Fill with mode
        else:  # Numerical column
            df2[col].fillna(df2[col].median(), inplace=True)  # Fill with median

# Verify missing values are handled
print("\nMissing Values After Imputation:\n", df2.isnull().sum())

#Encoding categorical variables

label_encoders = {}  # Store encoders for future reference
categorical_cols = []

for col in df2.columns:
  if df2.dtypes[col]=='object':
    categorical_cols.append(col)

print(categorical_cols)

for col in categorical_cols:
  le=LabelEncoder()
  df2[col]=le.fit_transform(df2[col])
  label_encoders[col]=le

# Feature scaling for numerical features

standard_scaler=StandardScaler() #z-score normalisation
numerical_cols = ['Age', 'Height', 'Weight', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE']

print(numerical_cols)

for col in numerical_cols:
  df2[[col]]=standard_scaler.fit_transform(df2[[col]])

print(df2.head())

""" **MODEL BUILDING - ENSEMBLE METHODS**



"""

X2= df2.drop(columns=['NObeyesdad']) #feature variables
y2=df2['NObeyesdad'] #target variable

X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.3, random_state=42)

"""**VOTING CLASSIFIERS**"""

# Define classifiers
log_reg = LogisticRegression()
decision_tree = DecisionTreeClassifier()
naive_bayes = GaussianNB()
svm = SVC(probability=True)

"""**Hard Voting**"""

hard_voting = VotingClassifier(estimators=[('lr', log_reg), ('dt', decision_tree), ('nb', naive_bayes), ('svm', svm)], voting='hard')
hard_voting.fit(X2_train, y2_train)
hard_pred = hard_voting.predict(X2_test)
hard_acc = accuracy_score(y2_test, hard_pred)
print("Hard Voting Accuracy:", hard_acc)

"""**Soft Voting**"""

# Soft Voting Classifier
soft_voting = VotingClassifier(estimators=[('lr', log_reg), ('dt', decision_tree), ('nb', naive_bayes), ('svm', svm)], voting='soft')
soft_voting.fit(X2_train, y2_train)
soft_pred = soft_voting.predict(X2_test)
soft_acc = accuracy_score(y2_test, soft_pred)
print("Soft Voting Accuracy:", soft_acc)

"""**Random forest algorithm**"""

rf_model = RandomForestClassifier()
rf_model.fit(X2_train, y2_train)

y_pred_rf = rf_model.predict(X2_test)
rf_acc=accuracy_score(y2_test, y_pred_rf)
print(" Random forest accuracy : ", rf_acc)
print(classification_report(y2_test, y_pred_rf))

"""**AdaBoost**"""

ab_model = AdaBoostClassifier()
ab_model.fit(X2_train, y2_train)

y_pred_ab = ab_model.predict(X2_test)
ab_acc=accuracy_score(y2_test, y_pred_ab)
print(" AdaBoost accuracy : ",ab_acc )
print(classification_report(y2_test, y_pred_ab))

"""**XGBoost**"""

xg_model = XGBClassifier()

xg_model.fit(X2_train, y2_train)

y_pred_xg = xg_model.predict(X2_test)
xg_acc=accuracy_score(y2_test, y_pred_xg)
print(" XGBoost accuracy : ", xg_acc)
print(classification_report(y2_test, y_pred_xg))

"""**ACCURACY COMPARISON**"""

results = pd.DataFrame({
    'Model': ['Hard Voting', 'Soft Voting', 'Random Forest', 'AdaBoost', 'XGBoost'],
    'Accuracy': [hard_acc, soft_acc, rf_acc, ab_acc, xg_acc]
})

# Print results
print("\nModel Performance:")
print(results)

# Plot accuracy comparison
plt.figure(figsize=(10,6))
sns.barplot(x='Model', y='Accuracy', data=results, palette='coolwarm')
plt.ylim(0.1, 1.0)
plt.xlabel("Classification Model")
plt.ylabel("Accuracy")
plt.title("Model Accuracy Comparison")
plt.xticks(rotation=45)
plt.show()

"""**Does ensemble method improve the
accuracy of classification?**

*   Yes, ensemble methods generally improve the accuracy of classification.
*   Combining multiple models: Ensemble methods use multiple weak learners to make a stronger, more accurate model.

*   Reducing variance: Methods like Random Forest and Bagging reduce overfitting, making predictions more stable.
*   Better decision boundaries: Boosting methods like AdaBoost and XGBoost improve model performance by focusing on difficult-to-classify samples.





"""